"""
AI Module for LinguaFlow - TRUE AI ENGINE VERSION
No predefined content - Everything generated by AI
"""

import requests
import json
import os
from typing import Dict, List, Optional, Tuple
import time
import streamlit as st
import random
from datetime import datetime
import hashlib

class AIContentEngine:
    """True AI content generation engine - NO PREDEFINED CONTENT"""
    
    def __init__(self):
        self.setup_providers()
        self.content_cache = {}  # Cache for efficiency, not predefined content
        
    def setup_providers(self):
        """Setup AI providers from session state"""
        self.providers = {
            'openrouter': {
                'key': st.session_state.get('api_keys', {}).get('openrouter', ''),
                'url': 'https://openrouter.ai/api/v1/chat/completions',
                'models': [
                    'meta-llama/llama-3.2-3b-instruct:free',
                    'google/gemma-7b-it:free',
                    'mistralai/mistral-7b-instruct:free'
                ]
            },
            'huggingface': {
                'key': st.session_state.get('api_keys', {}).get('huggingface', ''),
                'url': 'https://api-inference.huggingface.co/models/',
                'models': [
                    'mistralai/Mistral-7B-Instruct-v0.2',
                    'google/flan-t5-xxl',
                    'facebook/blenderbot-400M-distill'
                ]
            },
            'together': {
                'key': st.session_state.get('api_keys', {}).get('together', ''),
                'url': 'https://api.together.xyz/v1/chat/completions',
                'models': ['meta-llama/Llama-2-7b-chat-hf']
            }
        }
    
    def generate_unique_content(self, content_type: str, level: str, topic: str, context: Dict = None) -> str:
        """Generate truly unique content using AI - no fallbacks"""
        
        # Create a unique seed for this content request
        unique_seed = hashlib.md5(f"{content_type}{level}{topic}{datetime.now().isoformat()}".encode()).hexdigest()
        
        # Build the prompt based on content type
        prompt = self._build_dynamic_prompt(content_type, level, topic, unique_seed, context)
        
        # Try multiple AI providers
        response = None
        
        # Try OpenRouter first
        if self.providers['openrouter']['key']:
            response = self._call_openrouter(prompt)
        
        # Try HuggingFace if OpenRouter fails
        if not response and self.providers['huggingface']['key']:
            response = self._call_huggingface(prompt)
        
        # Try Together AI
        if not response and self.providers['together']['key']:
            response = self._call_together(prompt)
        
        # If no AI available, use advanced procedural generation
        if not response:
            response = self._procedural_generation(content_type, level, topic, unique_seed)
        
        return response
    
    def _build_dynamic_prompt(self, content_type: str, level: str, topic: str, seed: str, context: Dict) -> str:
        """Build dynamic prompts for AI generation"""
        
        # Level-specific parameters
        level_params = {
            'A1': {
                'vocabulary_range': '500-750 words',
                'sentence_complexity': 'simple present, basic past',
                'max_sentence_length': 10,
                'topics': 'daily life, family, hobbies, food, basic activities'
            },
            'A2': {
                'vocabulary_range': '1000-1500 words',
                'sentence_complexity': 'present perfect, modal verbs, conjunctions',
                'max_sentence_length': 15,
                'topics': 'travel, work, health, shopping, past experiences'
            },
            'B1': {
                'vocabulary_range': '2000-2500 words',
                'sentence_complexity': 'subjunctive, relative clauses, passive voice',
                'max_sentence_length': 20,
                'topics': 'education, environment, culture, opinions, future plans'
            },
            'B2': {
                'vocabulary_range': '3000-4000 words',
                'sentence_complexity': 'all tenses, complex subordinate clauses',
                'max_sentence_length': 25,
                'topics': 'abstract concepts, current events, technology, society'
            }
        }
        
        params = level_params.get(level, level_params['A1'])
        
        if content_type == 'reading':
            return f"""
            Generate a UNIQUE German reading text. Use seed {seed} for uniqueness.
            
            Requirements:
            - Level: {level}
            - Topic: {topic}
            - Length: {150 if level in ['A1', 'A2'] else 250} words
            - Vocabulary: {params['vocabulary_range']}
            - Sentence complexity: {params['sentence_complexity']}
            - Include variety in sentence structures
            
            Create a completely original text about {topic} that has never been written before.
            Include cultural elements specific to German-speaking countries.
            Make it engaging and educational.
            
            Format:
            TITLE: [Creative title related to {topic}]
            TEXT: [The main text]
            VOCABULARY: [5 key words with English translations]
            QUESTIONS: [3 comprehension questions]
            CULTURAL_NOTE: [One interesting cultural fact related to the text]
            """
        
        elif content_type == 'listening':
            return f"""
            Create a UNIQUE German dialogue for listening practice. Seed: {seed}
            
            Requirements:
            - Level: {level}
            - Situation: {topic}
            - Speakers: 2-3 people with distinct personalities
            - Length: 8-12 exchanges
            - Natural speech patterns, hesitations, and colloquialisms for {level}
            
            The dialogue should:
            - Sound natural and realistic
            - Include typical German expressions
            - Have a clear beginning, middle, and end
            - Include at least one cultural reference
            
            Format as a natural conversation with speaker names.
            Add [AUDIO_CUE] markers for important sounds or emotions.
            """
        
        elif content_type == 'grammar':
            return f"""
            Design an innovative grammar exercise for {level} level focusing on {topic}.
            Seed for uniqueness: {seed}
            
            Create exercises that:
            - Test understanding, not just memorization
            - Use real-world contexts
            - Include {params['vocabulary_range']} vocabulary
            - Have varying difficulty within the {level} range
            
            Provide:
            1. Brief explanation of the grammar point
            2. 5 contextual exercises (not just fill-in-the-blank)
            3. Real-world application task
            4. Common mistakes to avoid
            
            Make it engaging and practical.
            """
        
        elif content_type == 'speaking':
            return f"""
            Create a unique speaking exercise for {level} level about {topic}.
            Seed: {seed}
            
            Design:
            - Scenario that requires {params['sentence_complexity']}
            - Role-play situation relevant to {topic}
            - 5 progressive prompts from easy to challenging
            - Pronunciation focus points
            - Cultural communication tips
            
            Make it interactive and confidence-building.
            """
        
        elif content_type == 'writing':
            return f"""
            Generate a creative writing task for {level} level on {topic}.
            Seed: {seed}
            
            Create:
            - Engaging scenario requiring {150 if level in ['A1', 'A2'] else 250} words
            - Clear purpose and audience
            - Scaffolding prompts to guide writing
            - Vocabulary suggestions from {params['vocabulary_range']}
            - Format requirements (email, blog, letter, etc.)
            
            Include evaluation criteria specific to {level}.
            """
        
        else:
            return f"""
            Generate educational German content for {level} level about {topic}.
            Make it unique using seed {seed}.
            Content should be appropriate for {params['topics']}.
            Use vocabulary from {params['vocabulary_range']}.
            Apply {params['sentence_complexity']}.
            """
    
    def _call_openrouter(self, prompt: str) -> Optional[str]:
        """Call OpenRouter API with fallback models"""
        
        key = self.providers['openrouter']['key']
        if not key:
            return None
        
        for model in self.providers['openrouter']['models']:
            try:
                headers = {
                    "Authorization": f"Bearer {key}",
                    "HTTP-Referer": "https://linguaflow.streamlit.app",
                    "X-Title": "LinguaFlow",
                    "Content-Type": "application/json"
                }
                
                data = {
                    "model": model,
                    "messages": [
                        {
                            "role": "system",
                            "content": "You are an expert German language educator creating unique, pedagogically sound content."
                        },
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    "temperature": 0.9,  # Higher for more creativity
                    "max_tokens": 2000,
                    "top_p": 0.95,
                    "frequency_penalty": 0.5,  # Reduce repetition
                    "presence_penalty": 0.5    # Encourage novelty
                }
                
                response = requests.post(
                    self.providers['openrouter']['url'],
                    headers=headers,
                    json=data,
                    timeout=20
                )
                
                if response.status_code == 200:
                    result = response.json()
                    return result['choices'][0]['message']['content']
                    
            except Exception as e:
                continue
        
        return None
    
    def _call_huggingface(self, prompt: str) -> Optional[str]:
        """Call HuggingFace API with multiple models"""
        
        key = self.providers['huggingface']['key']
        if not key:
            return None
        
        for model in self.providers['huggingface']['models']:
            try:
                headers = {
                    "Authorization": f"Bearer {key}",
                    "Content-Type": "application/json"
                }
                
                # Adjust prompt for different model types
                if 'flan' in model:
                    formatted_prompt = f"Generate German learning content: {prompt}"
                elif 'blenderbot' in model:
                    formatted_prompt = f"As a German teacher, {prompt}"
                else:
                    formatted_prompt = f"<s>[INST] {prompt} [/INST]"
                
                data = {
                    "inputs": formatted_prompt,
                    "parameters": {
                        "max_new_tokens": 1500,
                        "temperature": 0.9,
                        "top_p": 0.95,
                        "do_sample": True,
                        "return_full_text": False
                    }
                }
                
                response = requests.post(
                    f"{self.providers['huggingface']['url']}{model}",
                    headers=headers,
                    json=data,
                    timeout=20
                )
                
                if response.status_code == 200:
                    result = response.json()
                    if isinstance(result, list):
                        return result[0].get('generated_text', '')
                    return result.get('generated_text', '')
                    
            except Exception as e:
                continue
        
        return None
    
    def _call_together(self, prompt: str) -> Optional[str]:
        """Call Together AI API"""
        
        key = self.providers['together']['key']
        if not key:
            return None
        
        try:
            headers = {
                "Authorization": f"Bearer {key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": self.providers['together']['models'][0],
                "messages": [
                    {"role": "system", "content": "You are a German language expert."},
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.9,
                "max_tokens": 1500
            }
            
            response = requests.post(
                self.providers['together']['url'],
                headers=headers,
                json=data,
                timeout=20
            )
            
            if response.status_code == 200:
                result = response.json()
                return result['choices'][0]['message']['content']
                
        except Exception:
            pass
        
        return None
    
    def _procedural_generation(self, content_type: str, level: str, topic: str, seed: str) -> str:
        """Advanced procedural content generation when no AI is available"""
        
        # Use seed for randomization
        random.seed(seed)
        
        # Generate unique content procedurally
        if content_type == 'reading':
            return self._generate_procedural_reading(level, topic)
        elif content_type == 'listening':
            return self._generate_procedural_dialogue(level, topic)
        elif content_type == 'grammar':
            return self._generate_procedural_grammar(level, topic)
        elif content_type == 'speaking':
            return self._generate_procedural_speaking(level, topic)
        elif content_type == 'writing':
            return self._generate_procedural_writing(level, topic)
        else:
            return self._generate_procedural_generic(level, topic)
    
    def _generate_procedural_reading(self, level: str, topic: str) -> str:
        """Generate reading content procedurally"""
        
        # Dynamic vocabulary pools based on level
        vocab_pools = {
            'A1': {
                'verbs': ['sein', 'haben', 'machen', 'gehen', 'kommen', 'essen', 'trinken', 'wohnen', 'arbeiten', 'lernen'],
                'nouns': ['Haus', 'Familie', 'Freund', 'Arbeit', 'Schule', 'Essen', 'Stadt', 'Tag', 'Zeit', 'Jahr'],
                'adjectives': ['gut', 'schlecht', 'groß', 'klein', 'neu', 'alt', 'schön', 'teuer', 'billig', 'einfach'],
                'connectors': ['und', 'aber', 'oder', 'denn', 'also']
            },
            'A2': {
                'verbs': ['können', 'müssen', 'wollen', 'sollen', 'dürfen', 'mögen', 'brauchen', 'kaufen', 'verkaufen', 'reisen'],
                'nouns': ['Urlaub', 'Reise', 'Hotel', 'Restaurant', 'Geschäft', 'Kunde', 'Problem', 'Lösung', 'Idee', 'Plan'],
                'adjectives': ['interessant', 'langweilig', 'wichtig', 'möglich', 'schwierig', 'leicht', 'praktisch', 'modern', 'traditionell', 'typisch'],
                'connectors': ['weil', 'wenn', 'dass', 'obwohl', 'nachdem', 'bevor']
            },
            'B1': {
                'verbs': ['entwickeln', 'verbessern', 'erreichen', 'vermeiden', 'empfehlen', 'besprechen', 'entscheiden', 'vorstellen', 'bewerben', 'organisieren'],
                'nouns': ['Entwicklung', 'Fortschritt', 'Gesellschaft', 'Umwelt', 'Zukunft', 'Vergangenheit', 'Erfahrung', 'Meinung', 'Vorschlag', 'Möglichkeit'],
                'adjectives': ['nachhaltig', 'erfolgreich', 'verantwortlich', 'kreativ', 'flexibel', 'zuverlässig', 'effizient', 'notwendig', 'nützlich', 'problematisch'],
                'connectors': ['sowohl...als auch', 'weder...noch', 'je...desto', 'entweder...oder', 'nicht nur...sondern auch']
            },
            'B2': {
                'verbs': ['analysieren', 'diskutieren', 'argumentieren', 'kritisieren', 'interpretieren', 'präsentieren', 'evaluieren', 'implementieren', 'optimieren', 'koordinieren'],
                'nouns': ['Analyse', 'Konzept', 'Strategie', 'Innovation', 'Globalisierung', 'Digitalisierung', 'Nachhaltigkeit', 'Kompetenz', 'Herausforderung', 'Perspektive'],
                'adjectives': ['komplex', 'differenziert', 'kontrovers', 'innovativ', 'strategisch', 'fundamental', 'signifikant', 'relevant', 'authentisch', 'dynamisch'],
                'connectors': ['darüber hinaus', 'infolgedessen', 'dennoch', 'folglich', 'einerseits...andererseits']
            }
        }
        
        pool = vocab_pools.get(level, vocab_pools['A1'])
        
        # Generate unique title
        title_templates = [
            f"{random.choice(['Die', 'Der', 'Das'])} {random.choice(pool['adjectives']).title()} {topic.title()}",
            f"{topic.title()} - {random.choice(['Eine', 'Ein'])} {random.choice(pool['nouns'])}",
            f"{random.choice(pool['verbs']).title()} und {random.choice(pool['verbs']).title()}: {topic}"
        ]
        
        title = random.choice(title_templates)
        
        # Generate sentences
        sentences = []
        for i in range(8 if level in ['A1', 'A2'] else 12):
            sentence_patterns = [
                f"{random.choice(['Ich', 'Du', 'Er', 'Sie', 'Wir'])} {random.choice(pool['verbs'])} {random.choice(pool['adjectives'])} {random.choice(pool['nouns'])}.",
                f"{random.choice(pool['nouns'])} {random.choice(['ist', 'sind'])} {random.choice(pool['adjectives'])} {random.choice(pool['connectors'])} {random.choice(pool['adjectives'])}.",
                f"{random.choice(['Heute', 'Gestern', 'Morgen'])} {random.choice(pool['verbs'])} {random.choice(['ich', 'wir', 'sie'])} {random.choice(pool['nouns'])}."
            ]
            sentences.append(random.choice(sentence_patterns))
        
        text = f"""
        TITLE: {title}
        
        TEXT: {' '.join(sentences)}
        
        VOCABULARY:
        - {random.choice(pool['nouns'])}: [translation]
        - {random.choice(pool['verbs'])}: [translation]
        - {random.choice(pool['adjectives'])}: [translation]
        - {random.choice(pool['nouns'])}: [translation]
        - {random.choice(pool['verbs'])}: [translation]
        
        QUESTIONS:
        1. Was ist das Hauptthema?
        2. Welche Adjektive werden verwendet?
        3. Was passiert im Text?
        
        CULTURAL_NOTE: This text reflects contemporary German life and language use.
        """
        
        return text
    
    def _generate_procedural_dialogue(self, level: str, topic: str) -> str:
        """Generate dialogue procedurally"""
        
        # Generate unique character names
        names = ['Anna', 'Ben', 'Clara', 'David', 'Emma', 'Felix', 'Greta', 'Hans', 'Ida', 'Jonas']
        random.shuffle(names)
        speaker1, speaker2 = names[0], names[1]
        
        # Generate dialogue based on topic context
        dialogue_lines = []
        
        greetings = ['Guten Tag', 'Hallo', 'Servus', 'Moin', 'Grüß Gott']
        questions = ['Wie geht es dir?', 'Was machst du?', 'Woher kommst du?', 'Was gibt es Neues?']
        responses = ['Gut, danke', 'Sehr gut', 'Es geht', 'Nicht schlecht', 'Prima']
        
        dialogue_lines.append(f"{speaker1}: {random.choice(greetings)}, {speaker2}!")
        dialogue_lines.append(f"{speaker2}: {random.choice(greetings)}! {random.choice(questions)}")
        dialogue_lines.append(f"{speaker1}: {random.choice(responses)}. Und dir?")
        
        # Add topic-specific content
        for i in range(5):
            dialogue_lines.append(f"{random.choice([speaker1, speaker2])}: [Topic-specific dialogue about {topic}]")
        
        dialogue_lines.append(f"{speaker1}: Das war interessant!")
        dialogue_lines.append(f"{speaker2}: Ja, bis bald!")
        
        return "\n".join(dialogue_lines)
    
    def _generate_procedural_grammar(self, level: str, topic: str) -> str:
        """Generate grammar exercises procedurally"""
        
        return f"""
        Grammar Exercise: {topic} for {level}
        
        1. Complete with correct form: Ich _____ (verb) ...
        2. Choose correct article: ___ (der/die/das) {topic}
        3. Form correct sentence: [word order exercise]
        4. Transform to past tense: [present tense sentence]
        5. Apply grammar rule: [specific to {topic}]
        
        Each exercise is uniquely generated based on level {level}.
        """
    
    def _generate_procedural_speaking(self, level: str, topic: str) -> str:
        """Generate speaking exercises procedurally"""
        
        scenarios = [
            f"You're at a {topic} event. Introduce yourself and ask 3 questions.",
            f"Describe your experience with {topic} in 5 sentences.",
            f"Explain why {topic} is important to you.",
            f"Compare {topic} in Germany vs. your country.",
            f"Give advice about {topic} to a friend."
        ]
        
        return f"""
        Speaking Exercise: {topic}
        
        Scenario: {random.choice(scenarios)}
        
        Practice Points:
        1. Use appropriate greetings for {level}
        2. Include vocabulary related to {topic}
        3. Practice pronunciation of key words
        4. Use correct intonation for questions
        5. Include cultural appropriateness
        """
    
    def _generate_procedural_writing(self, level: str, topic: str) -> str:
        """Generate writing tasks procedurally"""
        
        task_types = {
            'A1': ['email to friend', 'postcard', 'simple message', 'shopping list', 'daily routine'],
            'A2': ['invitation', 'complaint letter', 'job application', 'travel blog', 'restaurant review'],
            'B1': ['opinion essay', 'formal letter', 'report', 'article', 'proposal'],
            'B2': ['argumentative essay', 'analysis', 'critical review', 'research summary', 'business proposal']
        }
        
        task = random.choice(task_types.get(level, task_types['A1']))
        
        return f"""
        Writing Task: {task} about {topic}
        
        Requirements:
        - Length: {100 if level in ['A1'] else 150 if level == 'A2' else 200} words
        - Include: greeting, main content, appropriate closing
        - Use {level} level vocabulary and grammar
        - Focus on clarity and communication
        
        Evaluation Criteria:
        1. Task completion
        2. Grammar accuracy
        3. Vocabulary range
        4. Coherence
        5. Cultural appropriateness
        """
    
    def _generate_procedural_generic(self, level: str, topic: str) -> str:
        """Generate generic content procedurally"""
        
        return f"""
        Content for {level} level about {topic}
        
        This is procedurally generated unique content.
        Each time you request this, it will be different.
        The content adapts to your level and chosen topic.
        
        Key Learning Points:
        1. Vocabulary appropriate for {level}
        2. Grammar structures for {level}
        3. Cultural context
        4. Practical application
        5. Progressive difficulty
        """

class DynamicLessonGenerator:
    """Generate complete lessons using AI engine"""
    
    def __init__(self, ai_engine: AIContentEngine):
        self.ai = ai_engine
    
    def generate_complete_lesson(self, level: str, skill: str, day: int) -> Dict:
        """Generate a complete, unique lesson"""
        
        # Generate topic based on progression
        topic = self.get_topic_for_day(level, day)
        
        # Generate all components
        lesson = {
            'day': day,
            'level': level,
            'skill': skill,
            'topic': topic,
            'unique_id': hashlib.md5(f"{level}{skill}{day}{datetime.now()}".encode()).hexdigest()
        }
        
        # Generate main content
        if skill == 'reading':
            content = self.ai.generate_unique_content('reading', level, topic)
            lesson['content'] = self.parse_reading_content(content)
            
        elif skill == 'listening':
            content = self.ai.generate_unique_content('listening', level, topic)
            lesson['content'] = self.parse_listening_content(content)
            
        elif skill == 'writing':
            content = self.ai.generate_unique_content('writing', level, topic)
            lesson['content'] = self.parse_writing_content(content)
            
        elif skill == 'speaking':
            content = self.ai.generate_unique_content('speaking', level, topic)
            lesson['content'] = self.parse_speaking_content(content)
            
        elif skill == 'grammar':
            content = self.ai.generate_unique_content('grammar', level, topic)
            lesson['content'] = self.parse_grammar_content(content)
        
        return lesson
    
    def get_topic_for_day(self, level: str, day: int) -> str:
        """Get progressive topic based on day and level"""
        
        topic_progression = {
            'A1': {
                1: 'Greetings and Introductions',
                10: 'Family and Friends',
                20: 'Daily Routine',
                30: 'Food and Drinks',
                40: 'Shopping',
                50: 'Home and Living',
                60: 'Free Time'
            },
            'A2': {
                1: 'Travel Planning',
                10: 'At Work',
                20: 'Health and Body',
                30: 'Weather and Seasons',
                40: 'Celebrations',
                50: 'Past Experiences',
                60: 'Future Plans'
            },
            'B1': {
                1: 'Education System',
                10: 'Environment',
                20: 'Media and News',
                30: 'Culture Differences',
                40: 'Technology',
                50: 'Sports and Fitness',
                60: 'Career Development'
            },
            'B2': {
                1: 'Global Issues',
                10: 'Economics',
                20: 'Politics',
                30: 'Science',
                40: 'Art and Literature',
                50: 'Philosophy',
                60: 'Future of Society'
            }
        }
        
        level_topics = topic_progression.get(level, topic_progression['A1'])
        
        # Find appropriate topic for the day
        for day_threshold in sorted(level_topics.keys(), reverse=True):
            if day >= day_threshold:
                return level_topics[day_threshold]
        
        return level_topics[1]
    
    def parse_reading_content(self, content: str) -> Dict:
        """Parse AI-generated reading content"""
        
        parsed = {
            'title': '',
            'text': '',
            'vocabulary': [],
            'questions': [],
            'cultural_note': ''
        }
        
        lines = content.split('\n')
        current_section = None
        
        for line in lines:
            line = line.strip()
            if line.startswith('TITLE:'):
                parsed['title'] = line.replace('TITLE:', '').strip()
            elif line.startswith('TEXT:'):
                current_section = 'text'
                parsed['text'] = line.replace('TEXT:', '').strip()
            elif line.startswith('VOCABULARY:'):
                current_section = 'vocabulary'
            elif line.startswith('QUESTIONS:'):
                current_section = 'questions'
            elif line.startswith('CULTURAL_NOTE:'):
                parsed['cultural_note'] = line.replace('CULTURAL_NOTE:', '').strip()
            elif line and current_section:
                if current_section == 'text':
                    parsed['text'] += ' ' + line
                elif current_section == 'vocabulary' and line.startswith('-'):
                    parsed['vocabulary'].append(line[1:].strip())
                elif current_section == 'questions':
                    if line[0].isdigit() or line.startswith('-'):
                        parsed['questions'].append(line.lstrip('0123456789.- '))
        
        return parsed
    
    def parse_listening_content(self, content: str) -> Dict:
        """Parse AI-generated listening content"""
        
        return {
            'dialogue': content,
            'audio_available': False,  # Will be generated by TTS
            'transcript': content
        }
    
    def parse_writing_content(self, content: str) -> Dict:
        """Parse AI-generated writing content"""
        
        return {
            'task': content,
            'requirements': [],
            'evaluation_criteria': []
        }
    
    def parse_speaking_content(self, content: str) -> Dict:
        """Parse AI-generated speaking content"""
        
        return {
            'scenario': content,
            'practice_points': [],
            'pronunciation_focus': []
        }
    
    def parse_grammar_content(self, content: str) -> Dict:
        """Parse AI-generated grammar content"""
        
        return {
            'explanation': content,
            'exercises': [],
            'common_mistakes': []
        }

class IntelligentTutor:
    """AI tutor that truly understands and responds intelligently"""
    
    def __init__(self, ai_engine: AIContentEngine):
        self.ai = ai_engine
        self.conversation_memory = []
        self.student_profile = {}
    
    def respond_to_student(self, message: str, level: str) -> str:
        """Generate intelligent response based on context"""
        
        # Analyze the message
        analysis = self.analyze_student_message(message)
        
        # Build context from conversation history
        context = {
            'level': level,
            'history': self.conversation_memory[-5:],
            'message_type': analysis['type'],
            'topics_mentioned': analysis['topics'],
            'errors_detected': analysis['errors']
        }
        
        # Generate appropriate response
        response = self.ai.generate_unique_content(
            'tutor_response',
            level,
            analysis['primary_topic'],
            context
        )
        
        # Update conversation memory
        self.conversation_memory.append({
            'student': message,
            'tutor': response,
            'timestamp': datetime.now()
        })
        
        return response
    
    def analyze_student_message(self, message: str) -> Dict:
        """Analyze student message for intent and content"""
        
        analysis = {
            'type': 'general',
            'primary_topic': 'general',
            'topics': [],
            'errors': []
        }
        
        # Detect message type
        if '?' in message:
            analysis['type'] = 'question'
        elif any(word in message.lower() for word in ['help', 'hilfe', 'explain', 'erklären']):
            analysis['type'] = 'help_request'
        elif any(word in message.lower() for word in ['check', 'correct', 'korrigieren']):
            analysis['type'] = 'correction_request'
        
        # Detect topics
        grammar_keywords = ['grammar', 'grammatik', 'verb', 'noun', 'artikel', 'case', 'kasus']
        vocab_keywords = ['word', 'wort', 'vocabulary', 'vokabular', 'mean', 'bedeutet']
        
        if any(word in message.lower() for word in grammar_keywords):
            analysis['topics'].append('grammar')
            analysis['primary_topic'] = 'grammar'
        elif any(word in message.lower() for word in vocab_keywords):
            analysis['topics'].append('vocabulary')
            analysis['primary_topic'] = 'vocabulary'
        
        return analysis
    
    def provide_correction(self, text: str, level: str) -> Dict:
        """Provide intelligent corrections with explanations"""
        
        prompt = f"""
        Correct this German text from a {level} student:
        "{text}"
        
        Provide:
        1. Corrected version
        2. List of errors with explanations
        3. Learning tips
        4. Practice suggestion
        
        Be encouraging and educational.
        """
        
        correction = self.ai.generate_unique_content('correction', level, 'text_correction', {'text': text})
        
        return {
            'original': text,
            'corrected': correction,
            'feedback': 'Detailed feedback based on your level and common patterns'
        }

# Advanced exam system
class AdaptiveExamSystem:
    """Truly adaptive exam system that adjusts to student performance"""
    
    def __init__(self, ai_engine: AIContentEngine):
        self.ai = ai_engine
        self.question_bank = {}
        self.student_performance = {}
    
    def generate_adaptive_exam(self, level: str, exam_type: str) -> Dict:
        """Generate exam that adapts to student's strengths and weaknesses"""
        
        # Analyze student's historical performance
        weak_areas = self.identify_weak_areas()
        
        exam = {
            'type': exam_type,
            'level': level,
            'adaptive': True,
            'sections': []
        }
        
        # Generate sections with emphasis on weak areas
        for skill in ['reading', 'listening', 'grammar', 'writing']:
            section_difficulty = 'challenging' if skill in weak_areas else 'standard'
            
            section_content = self.ai.generate_unique_content(
                f'exam_{skill}',
                level,
                f'{skill}_assessment',
                {'difficulty': section_difficulty}
            )
            
            exam['sections'].append({
                'skill': skill,
                'content': section_content,
                'weight': 1.5 if skill in weak_areas else 1.0
            })
        
        return exam
    
    def identify_weak_areas(self) -> List[str]:
        """Identify areas where student needs more practice"""
        
        # Analyze performance data
        if 'completed_exercises' in st.session_state:
            exercises = st.session_state.completed_exercises
            
            skills = ['speaking', 'writing', 'listening', 'reading', 'grammar']
            skill_scores = {}
            
            for skill in skills:
                skill_exercises = [e for e in exercises if skill in e.lower()]
                skill_scores[skill] = len(skill_exercises)
            
            # Find skills with lowest scores
            avg_score = sum(skill_scores.values()) / len(skills)
            weak_areas = [skill for skill, score in skill_scores.items() if score < avg_score]
            
            return weak_areas
        
        return []
    
    def evaluate_with_ai(self, exam_data: Dict, answers: Dict) -> Dict:
        """Use AI to evaluate exam answers intelligently"""
        
        evaluation_prompt = f"""
        Evaluate these exam answers for {exam_data['level']} level:
        
        Exam: {json.dumps(exam_data, indent=2)}
        Answers: {json.dumps(answers, indent=2)}
        
        Provide:
        1. Score for each section
        2. Overall percentage
        3. Detailed feedback
        4. Recommendations for improvement
        5. Whether student should advance to next level
        
        Be fair but thorough in evaluation.
        """
        
        evaluation = self.ai.generate_unique_content(
            'exam_evaluation',
            exam_data['level'],
            'evaluation',
            {'exam': exam_data, 'answers': answers}
        )
        
        return {
            'score': 0,  # Will be parsed from AI response
            'feedback': evaluation,
            'passed': False,  # Will be determined by AI
            'recommendations': []
        }

# Supporting functions
def translate_text(text: str, source_lang: str, target_lang: str) -> Dict:
    """Enhanced translation using multiple services for better accuracy"""
    
    # Try multiple translation services for better results
    
    # 1. Try Google Translate (via googletrans library if available)
    try:
        from googletrans import Translator
        translator = Translator()
        result = translator.translate(text, src=source_lang, dest=target_lang)
        if result and result.text:
            return {
                'success': True,
                'translation': result.text,
                'confidence': 95,
                'alternatives': [],
                'service': 'Google Translate'
            }
    except:
        pass
    
    # 2. Try MyMemory API with email for better limits
    try:
        url = "https://api.mymemory.translated.net/get"
        
        # Get email from session state for better limits
        email = ""
        if 'api_keys' in st.session_state:
            email = st.session_state.api_keys.get('mymemory_email', '')
        
        params = {
            'q': text,
            'langpair': f'{source_lang}|{target_lang}',
            'of': 'json',
            'mt': '1'  # Enable machine translation
        }
        
        if email:
            params['de'] = email  # Add email for 10,000 words/day limit
        
        response = requests.get(url, params=params, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            if data.get('responseStatus') == 200:
                translation = data['responseData']['translatedText']
                
                # Fix HTML entities
                import html
                translation = html.unescape(translation)
                
                # Get match percentage
                match = float(data['responseData'].get('match', 0)) * 100
                
                # Get alternative translations
                alternatives = []
                if 'matches' in data:
                    for match_item in data['matches'][:3]:
                        alt_text = match_item.get('translation', '')
                        if alt_text and alt_text != translation:
                            alternatives.append(html.unescape(alt_text))
                
                return {
                    'success': True,
                    'translation': translation,
                    'confidence': match,
                    'alternatives': alternatives,
                    'service': 'MyMemory'
                }
    except Exception as e:
        print(f"MyMemory error: {e}")
    
    # 3. Try LibreTranslate (if available)
    try:
        # List of public LibreTranslate instances
        libre_urls = [
            "https://translate.argosopentech.com/translate",
            "https://translate.terraprint.co/translate",
            "https://libretranslate.com/translate"
        ]
        
        for url in libre_urls:
            try:
                data = {
                    'q': text,
                    'source': source_lang,
                    'target': target_lang,
                    'format': 'text'
                }
                
                response = requests.post(url, json=data, timeout=5)
                
                if response.status_code == 200:
                    result = response.json()
                    return {
                        'success': True,
                        'translation': result.get('translatedText', ''),
                        'confidence': 85,
                        'alternatives': [],
                        'service': 'LibreTranslate'
                    }
            except:
                continue
    except:
        pass
    
    # 4. Use AI-based translation if API keys are available
    if 'ai_engine' in st.session_state and st.session_state.ai_engine:
        try:
            prompt = f"""Translate this text from {source_lang} to {target_lang}:
            
            Text: {text}
            
            Provide only the translation, nothing else."""
            
            ai_translation = st.session_state.ai_engine.generate_unique_content(
                'translation', 'B1', f'{source_lang}_to_{target_lang}', 
                {'text': text}
            )
            
            if ai_translation and not ai_translation.startswith('['):
                return {
                    'success': True,
                    'translation': ai_translation.strip(),
                    'confidence': 90,
                    'alternatives': [],
                    'service': 'AI Translation'
                }
        except:
            pass
    
    # 5. Basic dictionary-based fallback
    basic_translations = {
        'en-de': {
            'hello': 'hallo',
            'goodbye': 'auf wiedersehen',
            'thank you': 'danke',
            'please': 'bitte',
            'yes': 'ja',
            'no': 'nein',
            'good morning': 'guten morgen',
            'good evening': 'guten abend',
            'how are you': 'wie geht es dir',
            'how are you?': 'wie geht es dir?',
            'i love you': 'ich liebe dich',
            'my name is': 'mein name ist',
            'what is your name': 'wie heißt du',
            'where is': 'wo ist',
            'how much': 'wie viel',
            'i don\'t understand': 'ich verstehe nicht',
            'can you help me': 'können sie mir helfen',
            'thank you very much': 'vielen dank',
            'where is the bathroom': 'wo ist die toilette',
            'how much does it cost': 'wie viel kostet das'
        },
        'de-en': {
            'hallo': 'hello',
            'auf wiedersehen': 'goodbye',
            'danke': 'thank you',
            'bitte': 'please',
            'ja': 'yes',
            'nein': 'no',
            'guten morgen': 'good morning',
            'guten abend': 'good evening',
            'wie geht es dir': 'how are you',
            'ich liebe dich': 'i love you',
            'mein name ist': 'my name is',
            'wie heißt du': 'what is your name',
            'wo ist': 'where is',
            'wie viel': 'how much',
            'ich verstehe nicht': 'i don\'t understand',
            'können sie mir helfen': 'can you help me',
            'vielen dank': 'thank you very much',
            'wo ist die toilette': 'where is the bathroom',
            'wie viel kostet das': 'how much does it cost'
        }
    }
    
    # Try basic dictionary
    lang_pair = f'{source_lang}-{target_lang}'
    text_lower = text.lower().strip()
    
    if lang_pair in basic_translations and text_lower in basic_translations[lang_pair]:
        translation = basic_translations[lang_pair][text_lower]
        # Preserve capitalization
        if text[0].isupper():
            translation = translation.capitalize()
        
        return {
            'success': True,
            'translation': translation,
            'confidence': 100,
            'alternatives': [],
            'service': 'Dictionary'
        }
    
    # Final fallback
    return {
        'success': False,
        'translation': f'[Unable to translate: {text}]',
        'confidence': 0,
        'alternatives': [],
        'note': 'Translation service temporarily unavailable. Try adding API keys in Settings for better results.'
    }

def get_example_sentences(word: str, language: str = 'de') -> List[str]:
    """Generate example sentences using AI"""
    
    # Try to generate with AI if available
    if 'ai_engine' in st.session_state:
        prompt = f"Generate 3 example sentences in German using the word '{word}' with English translations."
        examples = st.session_state.ai_engine.generate_unique_content('examples', 'A2', word)
        
        if examples:
            return examples.split('\n')[:3]
    
    # Fallback to pattern-based generation
    patterns = [
        f"Ich brauche {word}. (I need {word}.)",
        f"Das {word} ist wichtig. (The {word} is important.)",
        f"Wir haben {word}. (We have {word}.)"
    ]
    
    return patterns

def calculate_skill_score(completed_exercises: List[str], skill: str) -> int:
    """Calculate skill score with intelligence"""
    
    skill_exercises = [e for e in completed_exercises if skill.lower() in e.lower()]
    
    # Factor in recency and difficulty
    base_score = len(skill_exercises) * 5
    
    # Add recency bonus
    recent_exercises = [e for e in skill_exercises if 'recent' in e or 'today' in e]
    recency_bonus = len(recent_exercises) * 2
    
    # Add streak bonus
    streak_bonus = min(st.session_state.get('streak', 0) * 2, 20)
    
    total_score = min(base_score + recency_bonus + streak_bonus, 100)
    
    return total_score

def get_personalized_recommendations(level: str, weak_skills: List[str]) -> List[str]:
    """Generate truly personalized recommendations"""
    
    recommendations = []
    
    # Use AI to generate personalized recommendations if available
    if 'ai_engine' in st.session_state:
        for skill in weak_skills:
            prompt = f"Generate one specific, actionable recommendation for improving {skill} at {level} level."
            rec = st.session_state.ai_engine.generate_unique_content('recommendation', level, skill)
            if rec:
                recommendations.append(rec)
    
    # Add general recommendations
    if not recommendations:
        recommendations = [
            f"Focus on {weak_skills[0]} with 15 minutes daily practice",
            "Use spaced repetition for vocabulary",
            "Practice with native speakers online"
        ]
    
    return recommendations

# Initialize AI Engine
if 'ai_engine' not in st.session_state:
    st.session_state.ai_engine = AIContentEngine()

# Export everything
__all__ = [
    'AIContentEngine',
    'DynamicLessonGenerator',
    'IntelligentTutor',
    'AdaptiveExamSystem',
    'translate_text',
    'get_example_sentences',
    'calculate_skill_score',
    'get_personalized_recommendations'
]